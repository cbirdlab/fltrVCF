mean_viablebp_cutcut <- mean(frags_cutcut[which(frags_cutcut > 625)])
return(rbind(bp, stdev,numfragspostdigest, pcut, targetmeanfrag, meanfraglen, stdevfraglen, medianfraglen, modefraglen,numfrags_degdeg,numfrags_degcut, numfrags_cutcut,mean_bp_degdeg,mean_bp_degcut, mean_bp_cutcut, numviablefrags_degcut, numviablefrags_cutcut, mean_viablebp_degcut,mean_viablebp_cutcut))
}
lapply(seq(1000,2000,1000), function(x)
lapply(l, function(y) digestDNA(x,y)
)
)
#simulate digesting fragments of a given length distribution
rm(list=ls())
# bplist<-c()
# stdevlist<-c()
# numfragspostdigestlist<-c()
# pcutlist<-c()
# meanfraglenlist<-c()
# stdevfraglenlist<-c()
# medianfraglenlist<-c()
# modefraglenlist<-c()
# targetmeanfraglist<-c()
#
# frags_degdeg<-c()
# frags_degcut<-c()
# frags_cutcut<-c()
#
# numfrags_degdeg_list<-c()
# numfrags_degcut_list<-c()
# numfrags_cutcut_list<-c()
#
# mean_bp_degdeg_list<-c()
# mean_bp_degcut_list<-c()
# mean_bp_cutcut_list<-c()
#
# numviablefrags_degcut_list<-c()
# numviablefrags_cutcut_list<-c()
#
# mean_viablebp_degcut_list<-c()
mean_viablebp_cutcut_list<-c()
l=c(2500,5000, 7500, 10000, 15000, 20000, 40000, 80000, 160000)
#l=c(2500,5000)
#cycle through these settings
#for(k in c(1000,2500, 5000, 7500, 10000, 12500, 15000)){
digestDNA<- function(k,l){
bp<-l           #predigest frag length at peak RFU
stdev<-bp/10         #stdev of predigest frag length
numfrags<-round(10*(100000/bp)*(k/13000), 0)      #number of fragments to digest
pcut<-1/k     #probability of restriction site
postdigestfrags<-c() #vector of fragment lengths post digest
frags_degdeg<-c()
frags_degcut<-c()
frags_cutcut<-c()
for(j in 1:numfrags){
frags<-0
for(i in 1:round(rnorm(1,bp,(bp/20)),0)){
if(runif(1)<pcut){
#browser()
frags<-c(frags, i-sum(frags))
}
}
#browser()
frags<-c(frags, i-sum(frags))
len_frags<-length(frags)
if(len_frags==2){
frags_degdeg<-c(frags_degdeg,tail(frags, n=len_frags-1))
} else if (len_frags==3){
frags_degcut<-c(frags_degcut,tail(frags, n=len_frags-1))
} else {
frags_degcut<-c(frags_degcut,tail(frags, n=1), frags[2])
frags_cutcut<-c(frags_cutcut,head(tail(frags, n=len_frags-2), n=len_frags-2-1))
}
postdigestfrags<-c(postdigestfrags,tail(frags, n=len_frags-1))
}
pdf(paste(bp, stdev, round(pcut,6), (1/pcut)/bp,".pdf", sep="_"))
histout<-hist(postdigestfrags, breaks=100)
pseudoRFU<-histout$mids * histout$counts
plot(pseudoRFU ~ histout$mids, main=paste("Predigest: ", bp, "bp; Stdev Predigest: ", stdev, "bp; Probability of Restr Site: ", round(pcut,6), "; Ratio: ", (1/pcut)/bp))
plot(pseudoRFU ~ log10(histout$mids), main=paste("Predigest: ", bp, "bp; Stdev Predigest: ", stdev, "bp; Probability of Restr Site: ", round(pcut,6), "; Ratio: ", (1/pcut)/bp))
dev.off()
numfragspostdigest<- length(postdigestfrags)
targetmeanfrag<- 1/pcut
meanfraglen<- mean(postdigestfrags)
stdevfraglen<-  sd(postdigestfrags)
medianfraglen<- median(postdigestfrags)
modefraglen<- histout$mids[which(pseudoRFU == max(pseudoRFU))]
numfrags_degdeg<- length(frags_degdeg)
numfrags_degcut<- length(frags_degcut)
numfrags_cutcut<- length(frags_cutcut)
mean_bp_degdeg<- mean(frags_degdeg)
mean_bp_degcut<- mean(frags_degcut)
mean_bp_cutcut<- mean(frags_cutcut)
numviablefrags_degcut <- length(which(frags_degcut > 625))
numviablefrags_cutcut <- length(which(frags_cutcut > 625))
mean_viablebp_degcut <- mean(frags_degcut[which(frags_degcut > 625)])
mean_viablebp_cutcut <- mean(frags_cutcut[which(frags_cutcut > 625)])
return(rbind(bp, stdev,numfragspostdigest, pcut, targetmeanfrag, meanfraglen, stdevfraglen, medianfraglen, modefraglen,numfrags_degdeg,numfrags_degcut, numfrags_cutcut,mean_bp_degdeg,mean_bp_degcut, mean_bp_cutcut, numviablefrags_degcut, numviablefrags_cutcut, mean_viablebp_degcut,mean_viablebp_cutcut))
}
lapply(seq(1000,2000,1000), function(x)
lapply(l, function(y) digestDNA(x,y)
)
)
#simulate digesting fragments of a given length distribution
rm(list=ls())
l=c(2500,5000, 7500, 10000, 15000, 20000, 40000, 80000, 160000)
#l=c(2500,5000)
#cycle through these settings
#for(k in c(1000,2500, 5000, 7500, 10000, 12500, 15000)){
digestDNA<- function(k,l){
bp<-l           #predigest frag length at peak RFU
stdev<-bp/10         #stdev of predigest frag length
numfrags<-round(10*(100000/bp)*(k/13000), 0)      #number of fragments to digest
pcut<-1/k     #probability of restriction site
postdigestfrags<-c() #vector of fragment lengths post digest
frags_degdeg<-c()
frags_degcut<-c()
frags_cutcut<-c()
for(j in 1:numfrags){
frags<-0
for(i in 1:round(rnorm(1,bp,(bp/20)),0)){
if(runif(1)<pcut){
#browser()
frags<-c(frags, i-sum(frags))
}
}
#browser()
frags<-c(frags, i-sum(frags))
len_frags<-length(frags)
if(len_frags==2){
frags_degdeg<-c(frags_degdeg,tail(frags, n=len_frags-1))
} else if (len_frags==3){
frags_degcut<-c(frags_degcut,tail(frags, n=len_frags-1))
} else {
frags_degcut<-c(frags_degcut,tail(frags, n=1), frags[2])
frags_cutcut<-c(frags_cutcut,head(tail(frags, n=len_frags-2), n=len_frags-2-1))
}
postdigestfrags<-c(postdigestfrags,tail(frags, n=len_frags-1))
}
pdf(paste(bp, stdev, round(pcut,6), (1/pcut)/bp,".pdf", sep="_"))
histout<-hist(postdigestfrags, breaks=100)
pseudoRFU<-histout$mids * histout$counts
plot(pseudoRFU ~ histout$mids, main=paste("Predigest: ", bp, "bp; Stdev Predigest: ", stdev, "bp; Probability of Restr Site: ", round(pcut,6), "; Ratio: ", (1/pcut)/bp))
plot(pseudoRFU ~ log10(histout$mids), main=paste("Predigest: ", bp, "bp; Stdev Predigest: ", stdev, "bp; Probability of Restr Site: ", round(pcut,6), "; Ratio: ", (1/pcut)/bp))
dev.off()
numfragspostdigest<- length(postdigestfrags)
targetmeanfrag<- 1/pcut
meanfraglen<- mean(postdigestfrags)
stdevfraglen<-  sd(postdigestfrags)
medianfraglen<- median(postdigestfrags)
modefraglen<- histout$mids[which(pseudoRFU == max(pseudoRFU))]
numfrags_degdeg<- length(frags_degdeg)
numfrags_degcut<- length(frags_degcut)
numfrags_cutcut<- length(frags_cutcut)
mean_bp_degdeg<- mean(frags_degdeg)
mean_bp_degcut<- mean(frags_degcut)
mean_bp_cutcut<- mean(frags_cutcut)
numviablefrags_degcut <- length(which(frags_degcut > 625))
numviablefrags_cutcut <- length(which(frags_cutcut > 625))
mean_viablebp_degcut <- mean(frags_degcut[which(frags_degcut > 625)])
mean_viablebp_cutcut <- mean(frags_cutcut[which(frags_cutcut > 625)])
return(rbind(bp, stdev,numfragspostdigest, pcut, targetmeanfrag, meanfraglen, stdevfraglen, medianfraglen, modefraglen,numfrags_degdeg,numfrags_degcut, numfrags_cutcut,mean_bp_degdeg,mean_bp_degcut, mean_bp_cutcut, numviablefrags_degcut, numviablefrags_cutcut, mean_viablebp_degcut,mean_viablebp_cutcut))
}
lapply(seq(1000,2000,1000), function(x)
lapply(l, function(y) digestDNA(x,y)
)
)
#simulate digesting fragments of a given length distribution
rm(list=ls())
l=c(2500,5000, 7500, 10000, 15000, 20000, 40000, 80000, 160000)
#l=c(2500,5000)
#cycle through these settings
#for(k in c(1000,2500, 5000, 7500, 10000, 12500, 15000)){
digestDNA<- function(k,l){
bp<-l           #predigest frag length at peak RFU
stdev<-bp/10         #stdev of predigest frag length
numfrags<-round(10*(100000/bp)*(k/13000), 0)      #number of fragments to digest
pcut<-1/k     #probability of restriction site
postdigestfrags<-c() #vector of fragment lengths post digest
frags_degdeg<-c()  #vector of fragment lengths for frags with degradation breaks at both ends
frags_degcut<-c()  #vector of fragment lengths for frags with degradation breaks at one end and a restriction cut at the other
frags_cutcut<-c()  #vector of fragment lengths for frags with restriction cuts at both ends
for(j in 1:numfrags){
frags<-0
for(i in 1:round(rnorm(1,bp,(bp/20)),0)){
if(runif(1)<pcut){
#browser()
frags<-c(frags, i-sum(frags))
}
}
#browser()
frags<-c(frags, i-sum(frags))
len_frags<-length(frags)
if(len_frags==2){
frags_degdeg<-c(frags_degdeg,tail(frags, n=len_frags-1))
} else if (len_frags==3){
frags_degcut<-c(frags_degcut,tail(frags, n=len_frags-1))
} else {
frags_degcut<-c(frags_degcut,tail(frags, n=1), frags[2])
frags_cutcut<-c(frags_cutcut,head(tail(frags, n=len_frags-2), n=len_frags-2-1))
}
postdigestfrags<-c(postdigestfrags,tail(frags, n=len_frags-1))
}
pdf(paste(bp, stdev, round(pcut,6), (1/pcut)/bp,".pdf", sep="_"))
histout<-hist(postdigestfrags, breaks=100)
pseudoRFU<-histout$mids * histout$counts
plot(pseudoRFU ~ histout$mids, main=paste("Predigest: ", bp, "bp; Stdev Predigest: ", stdev, "bp; Probability of Restr Site: ", round(pcut,6), "; Ratio: ", (1/pcut)/bp))
plot(pseudoRFU ~ log10(histout$mids), main=paste("Predigest: ", bp, "bp; Stdev Predigest: ", stdev, "bp; Probability of Restr Site: ", round(pcut,6), "; Ratio: ", (1/pcut)/bp))
dev.off()
numfragspostdigest<- length(postdigestfrags)
targetmeanfrag<- 1/pcut
meanfraglen<- mean(postdigestfrags)
stdevfraglen<-  sd(postdigestfrags)
medianfraglen<- median(postdigestfrags)
modefraglen<- histout$mids[which(pseudoRFU == max(pseudoRFU))]
numfrags_degdeg<- length(frags_degdeg)
numfrags_degcut<- length(frags_degcut)
numfrags_cutcut<- length(frags_cutcut)
mean_bp_degdeg<- mean(frags_degdeg)
mean_bp_degcut<- mean(frags_degcut)
mean_bp_cutcut<- mean(frags_cutcut)
numviablefrags_degcut <- length(which(frags_degcut > 625))
numviablefrags_cutcut <- length(which(frags_cutcut > 625))
mean_viablebp_degcut <- mean(frags_degcut[which(frags_degcut > 625)])
mean_viablebp_cutcut <- mean(frags_cutcut[which(frags_cutcut > 625)])
return(rbind(bp, stdev,numfragspostdigest, pcut, targetmeanfrag, meanfraglen, stdevfraglen, medianfraglen, modefraglen,numfrags_degdeg,numfrags_degcut, numfrags_cutcut,mean_bp_degdeg,mean_bp_degcut, mean_bp_cutcut, numviablefrags_degcut, numviablefrags_cutcut, mean_viablebp_degcut,mean_viablebp_cutcut))
}
lapply(seq(1000,2000,1000), function(x)
lapply(l, function(y) digestDNA(x,y)
)
)
call_consensus_nucleotide <- function(nuc){
#load variables
ACTG <- nuc[names(nuc) != "-" & names(nuc) != "n"]
N <- nuc["n"]
INDEL <- nuc["-"]
numACTG <- sum(ACTG)
numNuc <- sum(nuc)
#if there are at least 2 good nucleotide calls, then call the nucleotide
if(numACTG > 2){
nuc_call <- names(ACTG[which.max(ACTG)])
} else {
nuc_call <- "n"
}
return nuc_call
}
install.packages("rwty")
install.packages("bookdown")
install.packages("devtools")
install.packages("ape")
install.packages("phytools")
install.packages("geiger")
install.packages("OUwie")
devtools::install_github("graemetlloyd/Claddis")
install.packages(c("adaptivetau", "aqp", "backports", "bayesplot", "brms", "broom", "callr", "car", "carData", "caret", "checkmate", "class", "classInt", "clipr", "cluster", "colorspace", "cowplot", "cubature", "data.table", "dbplyr", "ddalpha", "deldir", "dendextend", "digest", "dimRed", "DT", "e1071", "expm", "flexmix", "FNN", "forcats", "fpc", "fs", "geometry", "ggfortify", "ggplot2", "ggpubr", "ggrepel", "ggsignif", "git2r", "googleVis", "gower", "gstat", "gtable", "haven", "highr", "Hmisc", "htmlTable", "httpuv", "httr", "igraph", "ipred", "jsonlite", "later", "lava", "lazyeval", "lme4", "lmtest", "maptools", "markdown", "mclust", "mime", "ModelMetrics", "modelr", "multcomp", "mvtnorm", "nloptr", "numDeriv", "openssl", "openxlsx", "permute", "pillar", "pkgbuild", "plotKML", "plotrix", "pls", "polynom", "prabclus", "processx", "progress", "ps", "purrr", "purrrlyr", "quantreg", "raster", "rcmdcheck", "RcppEigen", "readr", "readxl", "recipes", "remotes", "reprex", "reshape", "rgdal", "rgl", "rio", "robustbase", "RRPP", "RSAGA", "rstudioapi", "Rtsne", "rvest", "sandwich", "segmented", "sf", "sfsmisc", "shiny", "soilDB", "spData", "spdep", "StanHeaders", "stringi", "stringr", "TH.data", "tibble", "tidybayes", "tidyr", "units", "usethis", "vegan", "webshot", "XML", "xtable", "xts", "zip", "zoo"))
devtools::install_github("graemetlloyd/metatree")
version
x=100
factorial(x)
factorial(x)*factorial(x-1)
factorial(x)/factorial(x-1)
#eq 10 tajima 1989
n=100
for(i in 1:n-1){
cni <- (factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2i)*factorial(n+2*1-1)*i*(2*1-1)
}
print(factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2i)*factorial(n+2*1-1)*i*(2*1-1)
}
print(factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2i)*factorial(n+2*1-1)*i*(2*1-1))
for(i in seq(1, n-1)){
print(factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2i)*factorial(n+2*1-1)*i*(2*1-1))
}
seq(1, n-1)
#eq 10 tajima 1989
n=2
for(i in seq(1, n-1)){
print(factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2i)*factorial(n+2*1-1)*i*(2*1-1))
}
print((factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2i)*factorial(n+2*1-1)*i*(2*1-1)))
#eq 10 tajima 1989
n=2
for(i in seq(1, n-1)){
print((factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2i)*factorial(n+2*1-1)*i*(2*1-1)))
}
for(i in seq(2, n-1)){
print((factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2i)*factorial(n+2*1-1)*i*(2*1-1)))
}
#eq 10 tajima 1989
n=3
for(i in seq(2, n-1)){
print((factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2i)*factorial(n+2*1-1)*i*(2*1-1)))
}
seq(2, n-1)
factorial(n-1)
n
factorial(0)
#eq 10 tajima 1989
n=2
for(i in seq(1, n-1)){
print( (factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2i)*factorial(n+2*1-1)*i*(2*1-1)))
}
factorial(n-1)
factorial(n)
factorial(n-1)*factorial(n)*(4*i-1)
#eq 10 tajima 1989
n=2
for(i in seq(1, n-1)){
print( (factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2*i)*factorial(n+2*1-1)*i*(2*1-1)))
}
#eq 10 tajima 1989
n=3
for(i in seq(1, n-1)){
print( (factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2*i)*factorial(n+2*1-1)*i*(2*1-1)))
}
#eq 10 tajima 1989
n=2
for(i in seq(1, n-1)){
print( (factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2*i)*factorial(n+2*1-1)*i*(2*1-1)))
}
#eq 10 tajima 1989
n=3
for(i in seq(1, n-1)){
print( (factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2*i)*factorial(n+2*1-1)*i*(2*1-1)))
}
(factorial(n-1)*factorial(n)*(4*i-1))
i
n
factorial(n-2*i)
n-2*i
#eq 10 tajima 1989
n=3
seq(1, n/2)
n=3
for(i in seq(1, n/2)){
print( (factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2*i)*factorial(n+2*1-1)*i*(2*1-1)))
}
#eq 10 tajima 1989
n=2
for(i in seq(1, n/2)){
print( (factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2*i)*factorial(n+2*1-1)*i*(2*1-1)))
}
#eq 10 tajima 1989
n=5
for(i in seq(1, n/2)){
print( (factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2*i)*factorial(n+2*1-1)*i*(2*1-1)))
}
n=10
for(i in seq(1, n/2)){
print( (factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2*i)*factorial(n+2*1-1)*i*(2*1-1)))
}
n=50
for(i in seq(1, n/2)){
print( (factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2*i)*factorial(n+2*1-1)*i*(2*1-1)))
}
#eq 10 tajima 1989
n <- 50
cni <- 0
n <- 100
cni <- 0
for(i in seq(1, n/2)){
print( (factorial(n-1)*factorial(n)*(4*i-1)) / (factorial(n-2*i)*factorial(n+2*1-1)*i*(2*1-1)))
}
ramanujan <- function(n){
n*log(n) - n + log(n*(1 + 4*n*(1+2*n)))/6 + log(pi)/2
}
ramanujan <- function(n){
n*log(n) - n + log(n*(1 + 4*n*(1+2*n)))/6 + log(pi)/2
}
#eq 10 tajima 1989
n <- 100
cni <- 0
for(i in seq(1, n/2)){
print( (ramanujan(n-1)*ramanujan(n)*(4*i-1)) / (ramanujan(n-2*i)*ramanujan(n+2*1-1)*i*(2*1-1)))
}
seq(1, n/2)
#eq 10 tajima 1989
n <- 200
cni <- 0
for(i in seq(1, n/2)){
print( (ramanujan(n-1)*ramanujan(n)*(4*i-1)) / (ramanujan(n-2*i)*ramanujan(n+2*1-1)*i*(2*1-1)))
}
stocks <- data.frame(
time = as.Date('2009-01-01') + 0:9,
X = rnorm(10, 0, 1),
Y = rnorm(10, 0, 2),
Z = rnorm(10, 0, 4)
)
View(stocks)
library(tidyverse)
stocksm <- stocks %>% gather(stock, price, -time)
View(stocksm)
stocksm %>% spread(stock, price)
df <- data.frame(x = c("a", "b"), y = c(3, 4), z = c(5, 6))
View(df)
df %>% spread(x, y)
df %>% spread(x, y) %>% gather("x", "y", a:b, na.rm = TRUE)
df <- data.frame(row = rep(c(1, 51), each = 3),
var = c("Sepal.Length", "Species", "Species_num"),
value = c(5.1, "setosa", 1, 7.0, "versicolor", 2))
df %>% spread(var, value) %>% str
df %>% spread(var, value)
View(df)
rm(list=ls())
setwd("c:/")
getwd()
setwd("c:/Users")
setwd("c:/Users/cbird/Documents/")
getwd()
read.table(rbdiv.clusters.tsv)
read.table("rbdiv.clusters.tsv")
df <- read.table("rbdiv.clusters.tsv")
hist(df$V1)
hist(df$V1, breaks = 20)
hist(df$V1, breaks = 50)
hist(df$V1, breaks = 50, xmax=50000)
hist(df$V1, breaks = 50, xlim = c(0,50000))
hist(df$V1, breaks = 500, xlim = c(0,50000))
hist(df$V1, breaks = 500, xlim = c(0,20000))
hist(df$V1, breaks = 1000, xlim = c(0,20000))
hpd(df$V1)
quantile(df$V1, c(.05,.5..95))
quantile(df$V1, c(.05,.5,.95))
quantile(df$V1, c(0.01,.05,.5,.95,.99))
rm(list=ls())
#setwd("C:/Users/cbird/Documents/GCL/scripts/fltrVCF/scripts")
library(tidyverse)
library(gridExtra)
inputFile=PIRE_SiganusSpinus.J.15.15.Fltr041.5.ldepth.mean.contigs
inputFile="PIRE_SiganusSpinus.J.15.15.Fltr041.5.ldepth.mean.contigs"
#read in ldepth haps file
df <- read.table(inputFile, header=FALSE, sep='\t')
getwd()
setwd("C:/Users/cbird/Documents/GCL/scripts/fltrVCF/scripts/")
getwd()
#read in ldepth haps file
df <- read.table(inputFile, header=FALSE, sep='\t')
lowPCT_Mean_Mean_Cvg <- 0.01
highPCT_Mean_Mean_Cvg <- 0.99
lowPCT_Mean_CV_Cvg <- 0
highPCT_Mean_CV_Cvg <- 0.99
outputFile="PIRE_SiganusSpinus.J.15.15.Fltr041.5.ldepth.mean.contigs.plots.pdf"
colnames(df) <- c("Contig", "BP", "Mean_Mean_Cvg", "CV_Mean_Cvg", "Mean_CV_Cvg", "CV_CV_Cvg")
Cutoffs_Mean_Mean_Cvg <- quantile(df$Mean_Mean_Cvg, probs=c(lowPCT_Mean_Mean_Cvg, highPCT_Mean_Mean_Cvg))
Cutoffs_Mean_CV_Cvg <- quantile(df$Mean_CV_Cvg, probs=c(lowPCT_Mean_CV_Cvg , highPCT_Mean_CV_Cvg ))
lowPCT_Mean_CV_Cvg
min(df$Mean_CV_Cvg)
#note that I set thse to Mean_CV_Cvg because these do not exist in fltrVCF right
Cutoffs_CV_Mean_Cvg <- quantile(df$CV_Mean_Cvg, probs=c(lowPCT_Mean_CV_Cvg , highPCT_Mean_CV_Cvg ))
Cutoffs_CV_CV_Cvg <- quantile(df$CV_CV_Cvg, probs=c(lowPCT_Mean_CV_Cvg , highPCT_Mean_CV_Cvg ))
maxMean_Mean_Cvg <- max(df$Mean_Mean_Cvg)
maxMean_CV_Cvg <- max(df$Mean_CV_Cvg)
maxCV_Mean_Cvg <- max(df$CV_Mean_Cvg)
maxCV_CV_Cvg <- max(df$CV_CV_Cvg)
#make histograms for Mean_Mean_Cvg
p1_Mean_Mean_Cvg <- ggplot(df, aes(x=Mean_Mean_Cvg)) +
geom_histogram(color="black", fill="white", binwidth = 1) +
theme_classic() +
ggtitle("Mean of Mean Cvg") +
scale_x_continuous(limits = c(0, maxMean_Mean_Cvg))
df1 <- df[df$Mean_Mean_Cvg >= Cutoffs_Mean_Mean_Cvg[1] & df$Mean_Mean_Cvg <= Cutoffs_Mean_Mean_Cvg[2],]
p2_Mean_Mean_Cvg <- ggplot(df1, aes(x=Mean_Mean_Cvg)) +
geom_histogram(color="black", fill="white", binwidth = 1) +
theme_classic() +
ggtitle(paste("Mean of Mean Cvg: ", round(Cutoffs_Mean_Mean_Cvg[1],1), "< CVG <", round(Cutoffs_Mean_Mean_Cvg[2],1), sep=" ")) +
scale_x_continuous(limits = c(0, maxMean_Mean_Cvg))
#make histograms for Mean_CV_Cvg
p1_Mean_CV_Cvg <- ggplot(df, aes(x=Mean_CV_Cvg)) +
geom_histogram(color="black", fill="white", bins = 100) +
theme_classic() +
ggtitle("Mean of CV of Mean Cvg") +
scale_x_continuous(limits = c(0, maxMean_CV_Cvg))
df2 <- df[df$Mean_CV_Cvg >= Cutoffs_Mean_CV_Cvg[1] & df$Mean_CV_Cvg <= Cutoffs_Mean_CV_Cvg[2],]
p2_Mean_CV_Cvg <- ggplot(df2, aes(x=Mean_CV_Cvg)) +
geom_histogram(color="black", fill="white", bins = 100) +
theme_classic() +
ggtitle(paste("Mean of CV of Mean Cvg: ", round(Cutoffs_Mean_CV_Cvg[1],1), "< CVG <", round(Cutoffs_Mean_CV_Cvg[2],1), sep=" ")) +
scale_x_continuous(limits = c(0, maxMean_CV_Cvg))
#make histograms for CV_Mean_Cvg
p1_CV_Mean_Cvg <- ggplot(df, aes(x=CV_Mean_Cvg)) +
geom_histogram(color="black", fill="white", bins = 100) +
theme_classic() +
ggtitle("CV of Mean of Mean Cvg, Currently Not Filterable") +
scale_x_continuous(limits = c(0, maxCV_Mean_Cvg))
df3 <- df[df$CV_Mean_Cvg >= Cutoffs_CV_Mean_Cvg[1] & df$CV_Mean_Cvg <= Cutoffs_CV_Mean_Cvg[2],]
p2_CV_Mean_Cvg <- ggplot(df3, aes(x=CV_Mean_Cvg)) +
geom_histogram(color="black", fill="white", bins = 100) +
theme_classic() +
ggtitle(paste("Currently Not Filterable: CV of CV of Mean Cvg", round(Cutoffs_CV_Mean_Cvg[1],1), "< CVG <", round(Cutoffs_CV_Mean_Cvg[2],1), sep=" ")) +
scale_x_continuous(limits = c(0, maxCV_Mean_Cvg))
#make histograms for Mean_CV_Cvg
p1_CV_CV_Cvg <- ggplot(df, aes(x=CV_CV_Cvg)) +
geom_histogram(color="black", fill="white", bins = 100) +
theme_classic() +
ggtitle("CV of CV of Mean Cvg, Currently Not Filterable") +
scale_x_continuous(limits = c(0, maxCV_CV_Cvg))
df4 <- df[df$CV_CV_Cvg >= Cutoffs_CV_CV_Cvg[1] & df$CV_CV_Cvg <= Cutoffs_CV_CV_Cvg[2],]
p2_CV_CV_Cvg <- ggplot(df4, aes(x=CV_CV_Cvg)) +
geom_histogram(color="black", fill="white", bins = 100) +
theme_classic() +
ggtitle(paste("Currently Not Filterable", round(Cutoffs_CV_CV_Cvg[1],1), "< CVG <", round(Cutoffs_CV_CV_Cvg[2],1), sep=" ")) +
scale_x_continuous(limits = c(0, maxCV_CV_Cvg))
p1_Mean_Mean_Cvg
p2_Mean_Mean_Cvg
p1_Mean_CV_Cvg
p2_Mean_CV_Cvg
p1_CV_Mean_Cvg
p2_CV_Mean_Cvg
p1_CV_CV_Cvg
p2_CV_CV_Cvg
pdf(file=outputFile, width=8.5, height=11)
grid.arrange(p1_Mean_Mean_Cvg, p2_Mean_Mean_Cvg, ncol=1, nrow=2)
grid.arrange(p1_Mean_CV_Cvg, p2_Mean_CV_Cvg, ncol=1, nrow=2)
grid.arrange(p1_CV_Mean_Cvg, p2_CV_Mean_Cvg, ncol=1, nrow=2)
grid.arrange(p1_CV_CV_Cvg, p2_CV_CV_Cvg, ncol=1, nrow=2)
dev.off()
str()
str(df)
